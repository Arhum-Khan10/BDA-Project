{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDA Project: Create Your Own Spotify Experience\n",
    "\n",
    "### Feature Extraction and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group members:\n",
    "\n",
    "- Aaqib Ahmed Nazir (i22-1920),\n",
    "- Arhum Khan (i22-1967),\n",
    "- Ammar Khasif (i22-1968)\n",
    "\n",
    "##### Section: DS-D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries Used:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymongo\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('fma_metadata\\\\tracks.csv')\n",
    "genres = pd.read_csv('fma_metadata\\\\genres.csv')\n",
    "features = pd.read_csv('fma_metadata\\\\features.csv')\n",
    "echonest = pd.read_csv('fma_metadata\\\\echonest.csv')\n",
    "raw_albums = pd.read_csv('fma_metadata\\\\raw_albums.csv')\n",
    "raw_artists = pd.read_csv('fma_metadata\\\\raw_artists.csv')\n",
    "raw_genres = pd.read_csv('fma_metadata\\\\raw_genres.csv')\n",
    "raw_tracks = pd.read_csv('fma_metadata\\\\raw_tracks.csv')\n",
    "raw_echonest = pd.read_csv('fma_metadata\\\\raw_echonest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get artist name \n",
    "for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist found\n"
     ]
    }
   ],
   "source": [
    "def find_artist(artist_name):\n",
    "    artist_name = artist_name.lower()\n",
    "    raw_artists[\"artist_name\"] = raw_artists[\"artist_name\"].str.lower()\n",
    "\n",
    "    # Checking if artist is in the dataset\n",
    "    if artist_name.lower() in raw_artists[\"artist_name\"].values:\n",
    "        print(\"Artist found\")\n",
    "    else:\n",
    "        print(\"Artist not found\")\n",
    "\n",
    "\n",
    "artist_name = \"lucky dragons\"\n",
    "find_artist(artist_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract features from the audio files\n",
    "loads an audio file using Librosa library, then extracts three features: MFCC, spectral centroid, and zero-crossing rate. It caches the results for faster access later. If an error occurs, it prints an error message and returns empty arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(\"cache\", verbose=0)\n",
    "@memory.cache\n",
    "def extract_features(file):\n",
    "    try:\n",
    "        y, sr = librosa.load(file, sr=None)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
    "        return mfcc, spectral_centroid, zero_crossing_rate\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file}: {e}\")\n",
    "        return np.array([]), np.array([]), np.array([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Audio Feature Extraction\n",
    "utilizes parallel processing to extract audio features from each file concurrently, enhancing computational efficiency. It employs the os.walk function for directory traversal, Parallel from joblib for parallelism, and tqdm for a progress bar display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 386/386 [00:01<00:00, 223.41it/s]\n"
     ]
    }
   ],
   "source": [
    "AUDIO_DIR = r\"fma_small1\"\n",
    "\n",
    "# Getting all the audio files\n",
    "audio_files = []\n",
    "for root, dirs, files in os.walk(AUDIO_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mp3\"):\n",
    "            audio_files.append(os.path.join(root, file))\n",
    "\n",
    "# Extracting features in parallel\n",
    "features = Parallel(n_jobs=-1)(\n",
    "    delayed(extract_features)(file) for file in tqdm(audio_files, total=len(audio_files))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the extracted features \n",
    "for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# Unpack features\n",
    "mfcc_features, spectral_centroid_features, zero_crossing_rate_features = zip(*features)\n",
    "\n",
    "# Print the type of each feature\n",
    "print(type(mfcc_features))\n",
    "print(type(spectral_centroid_features))\n",
    "print(type(zero_crossing_rate_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(spectral_centroid_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to NumPy arrays\n",
    "mfcc_features_list = np.concatenate([f.T for f in mfcc_features if f.size > 0], axis=0)\n",
    "spectral_centroid_features_list = np.concatenate([f.T for f in spectral_centroid_features if f.size > 0], axis=0)\n",
    "zero_crossing_rate_features_list = np.concatenate([f.T for f in zero_crossing_rate_features if f.size > 0], axis=0)\n",
    "\n",
    "\n",
    "# RobustScaler for standardization\n",
    "normalizer = MinMaxScaler()\n",
    "robust_standardized_mfcc_features = normalizer.fit_transform(mfcc_features_list)\n",
    "normalized_spectral_centroid = normalizer.fit_transform(spectral_centroid_features_list)\n",
    "normalized_zero_crossing_rate = normalizer.fit_transform(zero_crossing_rate_features_list)\n",
    "\n",
    "# Display the first 5 rows of the normalized MFCC features\n",
    "# print(\"Standardized MFCC Features: \",robust_standardized_mfcc_features[:5])\n",
    "# print(\"________________________\")\n",
    "# print(\"Normalized Spectral Centrioid: \",normalized_spectral_centroid[:5])\n",
    "# print(\"________________________\")\n",
    "# print(\"Normalized Zero Crossing Rate: \",normalized_zero_crossing_rate[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Dimensionality Reduction\n",
    "applies PCA to reduce the dimensionality of the extracted features. It uses the PCA function from the scikit-learn library to perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16465878  0.24043767]\n",
      " [-0.28042835 -0.04276589]\n",
      " [-0.09782554 -0.11769146]\n",
      " ...\n",
      " [ 0.18282329  0.03536527]\n",
      " [ 0.15205988  0.00951085]\n",
      " [ 0.10313283 -0.00604354]]\n"
     ]
    }
   ],
   "source": [
    "# applying pca on the features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit and transform the standardized MFCC features\n",
    "pca_mfcc_features = pca.fit_transform(robust_standardized_mfcc_features)\n",
    "\n",
    "# Display the shape of the PCA features\n",
    "print(pca_mfcc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the normalized features to a npy\n",
    "# np.save('normalized_mfcc_features.npy', robust_standardized_mfcc_features)\n",
    "# np.save('normalized_spectral_centroid.npy', normalized_spectral_centroid)\n",
    "# np.save('normalized_zero_crossing_rate.npy', normalized_zero_crossing_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Audio Features to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"music_features\"]\n",
    "mfcc_collection = db[\"mfcc_features\"]\n",
    "spectral_centroid_collection = db[\"spectral_centroid\"]\n",
    "zero_crossing_rate_collection = db[\"zero_crossing_rate\"]\n",
    "\n",
    "# Converting the features to a list of dictionaries\n",
    "robust_standardized_mfcc_features_dict = [{\"value\": x.tolist()} for x in robust_standardized_mfcc_features]\n",
    "normalized_spectral_centroid_dict = [{\"value\": x.tolist()} for x in normalized_spectral_centroid]\n",
    "normalized_zero_crossing_rate_dict = [{\"value\": x.tolist()} for x in normalized_zero_crossing_rate]\n",
    "\n",
    "# Inserting the features into the collection\n",
    "mfcc_collection.insert_many(robust_standardized_mfcc_features_dict)\n",
    "spectral_centroid_collection.insert_many(normalized_spectral_centroid_dict)\n",
    "zero_crossing_rate_collection.insert_many(normalized_zero_crossing_rate_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the extracted features \n",
    "for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first document in the collection\n",
    "# print(mfcc_collection.find_one())\n",
    "# print(spectral_centroid_collection.find_one())\n",
    "# print(zero_crossing_rate_collection.find_one())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
