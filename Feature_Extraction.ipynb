{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymongo\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from joblib import Parallel, delayed, Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(librosa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('fma_metadata\\\\tracks.csv')\n",
    "genres = pd.read_csv('fma_metadata\\\\genres.csv')\n",
    "features = pd.read_csv('fma_metadata\\\\features.csv')\n",
    "echonest = pd.read_csv('fma_metadata\\\\echonest.csv')\n",
    "raw_albums = pd.read_csv('fma_metadata\\\\raw_albums.csv')\n",
    "raw_artists = pd.read_csv('fma_metadata\\\\raw_artists.csv')\n",
    "raw_genres = pd.read_csv('fma_metadata\\\\raw_genres.csv')\n",
    "raw_tracks = pd.read_csv('fma_metadata\\\\raw_tracks.csv')\n",
    "raw_echonest = pd.read_csv('fma_metadata\\\\raw_echonest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding a specifc artist in the raw_artist by using the name and if not found display a message\n",
    "def find_artist(artist_name):\n",
    "    # convert the artist_name column to lower case\n",
    "    artist_name = artist_name.lower()\n",
    "    raw_artists['artist_name'] = raw_artists['artist_name'].str.lower()\n",
    "    \n",
    "    # check if the artist_name is in the raw_artists dataframe\n",
    "    if artist_name.lower() in raw_artists['artist_name'].values:\n",
    "        print('Artist found')\n",
    "    else:\n",
    "        print('Artist not found')\n",
    "        \n",
    "        \n",
    "artist_name = 'lucky dragons'\n",
    "find_artist(artist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from soundfile import SoundFile\n",
    "\n",
    "# Path to the directory containing audio files\n",
    "directory_path = 'D:\\\\fma_small'\n",
    "\n",
    "# Initialize memory cache\n",
    "memory = Memory(location='./cache', verbose=0)\n",
    "\n",
    "# Initialize lists to store features and corresponding labels\n",
    "mfcc_features_list = []\n",
    "labels = []\n",
    "\n",
    "# Define a function to extract features from an audio file\n",
    "@memory.cache\n",
    "def extract_features(audio_file_path):\n",
    "    try:\n",
    "        with SoundFile(audio_file_path) as audio_file:\n",
    "            audio_signal = audio_file.read(dtype='float32')\n",
    "            sampling_rate = audio_file.samplerate\n",
    "        mfcc_features = librosa.feature.mfcc(y=audio_signal, sr=sampling_rate, n_mfcc=13)\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=audio_signal, sr=sampling_rate)\n",
    "        zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio_signal)\n",
    "        return mfcc_features.T, spectral_centroid.squeeze(), zero_crossing_rate.squeeze()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {audio_file_path}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Iterate through each folder (genre) in the directory\n",
    "for folder_name in os.listdir(directory_path):\n",
    "    genre_folder_path = os.path.join(directory_path, folder_name)\n",
    "\n",
    "    try:\n",
    "        # Use joblib to parallelize feature extraction across audio files\n",
    "        results = Parallel(n_jobs=-1)(\n",
    "            delayed(extract_features)(os.path.join(genre_folder_path, audio_file_name))\n",
    "            for audio_file_name in os.listdir(genre_folder_path)\n",
    "        )\n",
    "\n",
    "        # Unpack results and append features and labels\n",
    "        for mfcc_features, spectral_centroid, zero_crossing_rate in results:\n",
    "            if mfcc_features is not None:\n",
    "                mfcc_features_list.append(mfcc_features)\n",
    "                labels.append(folder_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing folder {genre_folder_path}: {e}\")\n",
    "\n",
    "# Concatenate MFCC features to create a single array\n",
    "mfcc_features_array = np.concatenate(mfcc_features_list)\n",
    "\n",
    "# Display the shape of the MFCC features array and labels\n",
    "print(mfcc_features_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RobustScaler for standardization\n",
    "robust_scaler = MinMaxScaler()\n",
    "robust_standardized_mfcc_features = robust_scaler.fit_transform(mfcc_features)\n",
    "\n",
    "# # Normalizer the stndardized features\n",
    "normalizer = Normalizer(\"l2\")\n",
    "normalized_spectral_centroid = normalizer.fit_transform(spectral_centroid.reshape(1, -1))\n",
    "normalized_zero_crossing_rate = normalizer.fit_transform(zero_crossing_rate.reshape(1, -1))\n",
    "\n",
    "# Display the first 5 rows of the normalized MFCC features\n",
    "print(\"Standardized MFCC Features: \",robust_standardized_mfcc_features[:5])\n",
    "print(\"________________________\")\n",
    "print(\"Normalized Spectral Centrioid: \",normalized_spectral_centroid[:5])\n",
    "print(\"________________________\")\n",
    "print(\"Normalized Zero Crossing Rate: \",normalized_zero_crossing_rate[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying pca on the features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit and transform the standardized MFCC features\n",
    "pca_mfcc_features = pca.fit_transform(robust_standardized_mfcc_features)\n",
    "\n",
    "# Display the shape of the PCA features\n",
    "print(pca_mfcc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the normalized features to a npy\n",
    "np.save('normalized_mfcc_features.npy', robust_standardized_mfcc_features)\n",
    "np.save('normalized_spectral_centroid.npy', normalized_spectral_centroid)\n",
    "np.save('normalized_zero_crossing_rate.npy', normalized_zero_crossing_rate)\n",
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the features to a mongoDB \n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"music_features\"]\n",
    "mfcc_collection = db[\"mfcc_features\"]\n",
    "spectral_centroid_collection = db[\"spectral_centroid\"]\n",
    "zero_crossing_rate_collection = db[\"zero_crossing_rate\"]\n",
    "\n",
    "# Insert the features into the collection\n",
    "# convert the features to a list\n",
    "# Convert the features to a list of dictionaries\n",
    "robust_standardized_mfcc_features = [ {\"value\": x} for x in robust_standardized_mfcc_features ]\n",
    "normalized_spectral_centroid = [ {\"value\": x} for x in normalized_spectral_centroid ]\n",
    "normalized_zero_crossing_rate = [ {\"value\": x} for x in normalized_zero_crossing_rate ]\n",
    "\n",
    "# Insert the features into the collection\n",
    "mfcc_collection.insert_many(robust_standardized_mfcc_features)\n",
    "spectral_centroid_collection.insert_many(normalized_spectral_centroid)\n",
    "zero_crossing_rate_collection.insert_many(normalized_zero_crossing_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first document in the collection\n",
    "print(mfcc_collection.find_one())\n",
    "print(spectral_centroid_collection.find_one())\n",
    "print(zero_crossing_rate_collection.find_one())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
